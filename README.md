# flow of the process from code.

[Source Code (.java)]
         |
       javac
         v
[Bytecode (.class)]
         |
       jar/pack
         v
[Executable Archive (.jar)]
         |
     java -jar
         v
   [JVM Instance]
         |
   (running in OS)
         v
   [OS Process: java]
         |
      Threads (Thread-1, Thread-2, ...)
         |
     Concurrency / Parallelism


# process

| Concept       | Description                                       | Example                              |
| ------------- | ------------------------------------------------- | ------------------------------------ |
| **Process**   | A running instance of a program managed by the OS | JVM running your Java app            |
| **Program**   | Static set of instructions on disk                | `MyApp.jar`                          |
| **Thread**    | Execution unit within a process                   | `Thread-0`, `main`                   |
| **Isolation** | Each process has its own memory space             | JVM separate from Chrome             |
| **Lifecycle** | Created â†’ Running â†’ Waiting â†’ Terminated          | `java` starts and exits after main() |


# thread 
| Concept              | Description                                                       | Example / Note                  |
| -------------------- | ----------------------------------------------------------------- | ------------------------------- |
| **Thread**           | Smallest unit of CPU execution within a process                   | Javaâ€™s `Thread` or `Runnable`   |
| **Main Thread**      | Runs `main()` method                                              | Always created by JVM           |
| **Thread Lifecycle** | NEW â†’ RUNNABLE â†’ RUNNING â†’ WAITING â†’ TERMINATED                   | Controlled by JVM scheduler     |
| **Shared Memory**    | Threads share heap; have separate stacks                          | Can lead to race conditions     |
| **Concurrency**      | Multiple threads executing logically at the same time             | Useful for multitasking         |
| **Parallelism**      | Threads executing *physically* at the same time on multiple cores | True simultaneous execution     |
| **Thread Cost**      | Lightweight compared to processes                                 | But not free â€” manage carefully |


# Threads vs Processes

| Feature            | **Process**                             | **Thread**                           |
| ------------------ | --------------------------------------- | ------------------------------------ |
| **Memory Space**   | Each process has its own memory         | Threads share memory                 |
| **Creation Cost**  | High (OS allocates new memory)          | Low (shares existing memory)         |
| **Communication**  | Via IPC (files, sockets)                | Direct via shared variables          |
| **Failure Impact** | One process crash doesnâ€™t affect others | One bad thread can crash the process |
| **Concurrency**    | Multi-process parallelism               | Multi-threaded concurrency           |


# Concurrency vs Parallelism

| Concept         | Definition                                                                                                                                |
| --------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Concurrency** | Doing *multiple things at once* (structurally overlapping tasks). Itâ€™s about *dealing with* many tasks at once.                           |
| **Parallelism** | Doing *multiple things literally at the same time* (simultaneously using multiple CPUs/cores). Itâ€™s about *executing* many tasks at once. |

# Analogy

| Scenario                                          | Concurrency                                                                      | Parallelism                                                         |
| ------------------------------------------------- | -------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| ğŸ§â€â™‚ï¸ One person cooking and talking on the phone | Switching between cooking and talking (one at a time, but tasks overlap in time) | Two people â€” one cooks, one talks (both actually happening at once) |
| ğŸ§µ In code                                        | One thread interleaving tasks                                                    | Multiple threads on different cores truly executing simultaneously  |


# ğŸ§± Basic Thread Program Flow in Java

| Step  | Code Element                       | Description                                                     | Example Snippet                                                  |
| ----- | ---------------------------------- | --------------------------------------------------------------- | ---------------------------------------------------------------- |
| **1** | **Define a Task**                  | Create a class that implements `Runnable` (or extend `Thread`). | `class MyTask implements Runnable { public void run() { ... } }` |
| **2** | **Create a Thread Object**         | Pass the task to a `Thread` instance.                           | `Thread t = new Thread(new MyTask());`                           |
| **3** | **Start the Thread**               | Call `start()` to tell JVM to run `run()` in a new thread.      | `t.start();`                                                     |
| **4** | **(Optional) Name Thread**         | Helps identify threads in logs/debugging.                       | `new Thread(new MyTask(), "Worker-1");`                          |
| **5** | **(Optional) Synchronize or Wait** | Use `join()` to wait for thread completion.                     | `t.join();`                                                      |
| **6** | **End of Execution**               | Thread terminates automatically when `run()` completes.         | â€”                                                                |


| Feature              | `Runnable`                            | `Callable<V>`                         |
| -------------------- | ------------------------------------- | ------------------------------------- |
| **Return value**     | Cannot return anything (`void run()`) | Returns a value (`V call()`)          |
| **Exceptions**       | Cannot throw checked exceptions       | Can throw checked exceptions          |
| **Method name**      | `run()`                               | `call()`                              |
| **Result retrieval** | Not possible                          | Via `Future.get()`                    |
| **Common use**       | Fire-and-forget tasks                 | Tasks that compute and return results |


# Race Condition ( adder subtracter problem.)

      This is a race condition â€” threads "race" to read/write a shared value.

| Feature / Aspect                                  | `synchronized`                                        | `ReentrantLock`                                                           |
| ------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------------- |
| **Type**                                          | Keyword (language-level)                              | Class (`java.util.concurrent.locks`)                                      |
| **Reentrancy**                                    | âœ… Yes (reentrant)                                     | âœ… Yes (reentrant)                                                         |
| **Lock acquisition**                              | Automatic when entering a synchronized block/method   | Manual via `lock()` and `unlock()`                                        |
| **Lock release**                                  | Automatic when method/block exits (even on exception) | Must be released manually in `finally` block                              |
| **Try to acquire lock (non-blocking)**            | âŒ Not possible                                        | âœ… `tryLock()` / `tryLock(timeout)`                                        |
| **Interruptible lock acquisition**                | âŒ No                                                  | âœ… `lockInterruptibly()`                                                   |
| **Condition variables (wait/notify alternative)** | `wait()`, `notify()`, `notifyAll()`                   | `Condition` objects (`newCondition()`)                                    |
| **Performance**                                   | Slightly faster for simple locking                    | More flexible but a bit heavier                                           |
| **Visibility (memory consistency)**               | Automatically handles visibility (like `volatile`)    | Also handles visibility via lock/unlock                                   |
| **Debugging / Monitoring**                        | Limited (no info on lock state)                       | âœ… Methods like `isLocked()`, `getHoldCount()`, `isHeldByCurrentThread()`  |


TIME â†’
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SharedResource                    â”‚
â”‚  count = 0                                                 â”‚
â”‚  lock = ReentrantLock@1234  (shared between both threads)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     Adder Thread     â”‚         â”‚  Subtractor Thread   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                  â”‚
             â”‚ lock.lock()                      â”‚
             â”‚  (lock free â†’ acquire)           â”‚
             â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
             â”‚ count++ (critical section)       â”‚
             â”‚                                  â”‚
             â”‚ lock.unlock()                    â”‚
             â”‚ releases â†’ notifies waiting      â”‚
             â”‚                                  â”‚
             â”‚                                  â”‚ lock.lock()
             â”‚                                  â”‚ (now free â†’ acquire)
             â”‚                                  â”‚
             â”‚                                  â”‚ count-- (critical section)
             â”‚                                  â”‚
             â”‚                                  â”‚ lock.unlock()
             â”‚                                  â”‚ (release)


# critical section

      A critical section is a part of a program where shared data is accessed or modified, and therefore only one thread must execute it at a time.

# What is preemptiveness?

      Preemptive multitasking means the operating system can interrupt (preempt) a running thread at any time to give CPU time to another thread.
      
      In simpler words:
            Threads donâ€™t politely take turns â€” the OS forces them to share the CPU fairly.

# What is context switching?

      Context switching is the process of saving the state of one thread (registers, program counter, stack, etc.) and loading the state of another thread â€” so the CPU can continue executing that one.

# What happens during a context switch (under the hood)

      1. Save current threadâ€™s state

            a. CPU registers (like program counter, stack pointer)

            b. Thread ID, scheduling info

      2. Select next runnable thread (based on priority, fairness, etc.)

      3. Load next threadâ€™s state

      4. CPU starts executing the new threadâ€™s instructions


# Deadlock
      A deadlock is a situation in multithreading where two or more threads are permanently blocked,
      each waiting for a resource (lock, monitor, etc.) that the other thread holds,
      and none of them can proceed.

| Aspect                               | Description                                                                                                                                                                                                                    |
| ------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Definition**                       | A state where threads are waiting on each other forever, preventing progress                                                                                                                                                   |
| **Main Cause**                       | Multiple locks acquired in **different orders** by different threads                                                                                                                                                           |
| **Necessary Conditions** (Coffmanâ€™s) | 1ï¸âƒ£ *Mutual exclusion* (locks are exclusive)<br>2ï¸âƒ£ *Hold and wait* (threads hold one resource while waiting for another)<br>3ï¸âƒ£ *No preemption* (locks canâ€™t be forcibly taken)<br>4ï¸âƒ£ *Circular wait* (thread A â†’ B â†’ C â†’ A) |
| **Symptoms**                         | Program hangs, high CPU idle, no exceptions thrown                                                                                                                                                                             |
| **Common Example**                   | Thread 1 locks `lockA` then waits for `lockB`; Thread 2 locks `lockB` then waits for `lockA`                                                                                                                                   |
| **In Java**                          | Happens with `synchronized`, `ReentrantLock`, or any blocking resource if lock ordering is inconsistent                                                                                                                        |
| **Detection**                        | Using `ThreadMXBean.findDeadlockedThreads()` or thread dumps (`jstack`)                                                                                                                                                        |
| **Prevention Techniques**            | âœ… Use **consistent lock order** across all threads<br>âœ… Use **tryLock(timeout)** to back off<br>âœ… Avoid nested locks when possible<br>âœ… Prefer **higher-level concurrent utilities** (`ConcurrentHashMap`, atomics)            |
| **Difference from Livelock**         | Deadlock â†’ threads are stuck doing *nothing*.<br>Livelock â†’ threads are *active* but keep changing state without progress.                                                                                                     |
| **Typical Fix**                      | Acquire locks in the **same sequence** everywhere (e.g., always `lock1 â†’ lock2`)                                                                                                                                               |
# What is a Semaphore?

      A semaphore is a synchronization mechanism that controls access to a shared resource by using a counter.

      Itâ€™s like a â€œgatekeeperâ€ â€” it decides how many threads are allowed to enter a critical section.

      Simple analogy

            Think of a parking lot with 3 spots (permits):

                  3 cars can park (3 permits).

                  If the lot is full (0 permits left), other cars must wait.

                  When one car leaves (releases), another can park.

# Types of Semaphores

| Type                   | Description                                | Java Class         |
| ---------------------- | ------------------------------------------ | ------------------ |
| **Binary Semaphore**   | Only 0 or 1 permit â†’ acts like a **mutex** | `new Semaphore(1)` |
| **Counting Semaphore** | Allows *n* concurrent threads              | `new Semaphore(n)` |

# What is a Mutex?
      A mutex (Mutual Exclusion) is a lock that allows only one thread at a time to access a resource.


# Producerâ€“Consumer Problem (Semaphore Version).
      The Producerâ€“Consumer Problem is a classic example of multi-thread synchronization in operating systems and concurrent programming.

      It describes two types of threads â€” Producers and Consumers â€” that share a fixed-size buffer.

# Problem Definition
      Producer threads generate data (items) and place them into a shared buffer.

      Consumer threads remove items from that buffer for processing.

      The buffer has a limited capacity (can hold only n items at once).

      Both must work without stepping on each otherâ€™s data and without race conditions.

# The Challenge
      A producer might try to add an item when the buffer is full â†’ causes overflow.

      A consumer might try to remove an item when the buffer is empty â†’ underflow.

      Both could access the buffer simultaneously, causing inconsistent data.
      
# The Semaphore Solution

| Semaphore | Purpose                                                                                      | Initial Value            |
| --------- | -------------------------------------------------------------------------------------------- | ------------------------ |
| `empty`   | Counts how many buffer slots are **free**                                                    | buffer capacity (e.g. 3) |
| `full`    | Counts how many items are **ready to consume**                                               | 0                        |
| `mutex`   | A **binary lock** (mutual exclusion) â€” ensures only one thread accesses the buffer at a time | 1                        |

# Flow of Execution

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚        Shared Buffer       â”‚
          â”‚  (Fixed Capacity Queue)    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                      â”‚
Producer Thread(s)                   Consumer Thread(s)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1ï¸âƒ£ Wait (empty--)                    1ï¸âƒ£ Wait (full--)
2ï¸âƒ£ Lock (mutex--)                    2ï¸âƒ£ Lock (mutex--)
3ï¸âƒ£ Add item                          3ï¸âƒ£ Remove item
4ï¸âƒ£ Unlock (mutex++)                  4ï¸âƒ£ Unlock (mutex++)
5ï¸âƒ£ Signal (full++)                   5ï¸âƒ£ Signal (empty++)

# Key Points Summary

| Concept                   | Description                                                                     |
| ------------------------- | ------------------------------------------------------------------------------- |
| **Goal**                  | Coordinate producers and consumers so they donâ€™t conflict when sharing a buffer |
| **Issue Solved**          | Prevents overflow, underflow, and race conditions                               |
| **Synchronization Tools** | Semaphores (`empty`, `full`, `mutex`)                                           |
| **Critical Section**      | The code that modifies the shared buffer (add/remove item)                      |
| **Mutex Role**            | Ensures only one thread accesses the buffer at a time                           |
| **Empty / Full**          | Control when threads wait or proceed based on buffer state                      |
| **Result**                | Safe, deadlock-free producer-consumer interaction                               |

